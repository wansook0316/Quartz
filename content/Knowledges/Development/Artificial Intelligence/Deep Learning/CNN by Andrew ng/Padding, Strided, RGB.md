---
title: Padding, Strided, RGB
thumbnail: ''
draft: false
tags:
- computer-vision
- deep-learning
- padding
- stride
- RGB
- convolution
created: 2023-10-04
---

# What is Padding Convolution

![](convolution1.png)

* 전 게시물에서 3x3 짜리 필터를 걸었을 때, 4x4짜리가 나왔다.

* 어떻게 보면 당연할 결과이다.

* 이미지의 한 변의 크기를 n, 필터의 한 변의 크기를 f라고 한다면,

* 출력의 한 변의 크기는,
  
  (*n* − *f* + 1) × (*n* − *f* + 1)

* 그런데 이렇게 된다면, 위 그림에서 6x6 짜리 행렬의 가장자리에 있는 픽셀들은

* 중간에 있는 픽셀보다 적은 횟수로 필터가 걸린다.

* 즉 ***데이터의 손실***이 생긴다.

* 두번째로는 ***이미지가 축소*** 된다는 단점이 있다.

![](convolution2.png)

* 내가 원하는 이런 결과가 나오기 위해서는 어떤 조치를 취해줘야한다.

![](convolution3.png)

* 다음과 같이 6x6 주변에 1짜리 테두리는 덧데어 (PAD) 주면, 해결된다!
* 이렇게 될때 데이터 손실, 이미지축소의 두가지 단점을 모두 잡을 수 있다.
* 패딩해주는 값은 0으로 보통 채운다.
* 내가 p를 패딩의 양이라고 하면 이때 p = 1이다.
* 이제 패딩까지 추가하여 결과이미지의 크기를 예상해보면, (*n* + 2*p* − *f* + 1) × (*n* + 2*p* − *f* + 1)

## Category of Padding

1. Vaild
   - ***No Padding***
   - p = 0
1. Same
   * 방금같은 3x3 필터의 경우 p = 1 일 때 출력값과 입력값의 크기가 동일함
   * 결론적으로 ***입력과 같은 크기의 출력을 갖게하는 패딩값***

$$
(n+2p-f+1) = n\\ p = {f-1\over2}
$$

거의 항상 필터는 홀수의 크기를 같고 있기 때문에 Padding은 정수값으로 떨어진다.

# What is Strided Convolution

![](convolution4.png)
![](convolution5.png)

* 지금까지 필터를 곱할때 한칸씩 띄면서 곱했는데,
* 두칸씩 띄어서 연산하자!
* 이게 스트라이드의 개념이다.
* 이걸 기존의 Fully connected Neural Network로 본다면,
* 신경망이 연결될 때 있어서, 공차를 몇으로 두겠냐는 의미와 상등하다.
* 자 그렇다면 이 경우, Stride 는 2이다.
* 이 경우 출력값은 3x3 이고, 이 관계를 나타내어 보면,

$$
({n+2p-f\over s}+1)\times({n+2p-f\over s}+1)
$$

* 이 때, 정수가 아니면 내림을 해준다.

$$
floor({n+2p-f\over s}+1)\times floor({n+2p-f\over s}+1)
$$

# Convolutions in RGB Channels

* 이제 밝기만 생각한 이미지로 부터, 실제 색을 나타내는 RGB로 확장해서 생각해보자.

![](convolution6.png)

* 이제 이런식으로 3개의 RGB 채널에 대해 3개의 필터를 사용해서 값을 받을 것이다.
* 그런데 한가지 주목해야 하는 점은 이미지의 채널 수와 필터의 채널 수는 같아야 한다는 점이다.
* 하지만 ***출력값의 채널수는 같을 필요가 없다.***

![](convolution7.png)

* 위의 그림을 조금더 간단하게 보면 다음과 같다.
* 이 때, 3 x 3 x 3의 필터를 정육면체 덩어리로 본다면,
* 이제 이 덩어리가 RGB 채널로 구성된 이미지에 한번씩 적용되는 형태이다.
* 그렇다면 필터의 요소는 총 9개로 구성된 텐서덩어리 이며, 이미지에 적용이 되면 총 27개의 값이 나온다.
* 그런데 우리는 Convolution 연산을 하므로 이 27개의 값을 다 더한 것이
* 출력의 \[1,1\]에 저장된다.
* 그렇기 때문에 4 x 4 x 3 이 아닌 4 x 4 x 1짜리 출력을 얻게 된다.

### 참고

* 텐서플로우에서 왜 노드의 연결이 텐서로 이루어진다고 했는지 위 예시에서 보다 확실하게 알 수 있다.
* 여기서 필터는 가중치 덩어리이기 때문이다.
* 그리고 왼쪽의 이미지는 Input data를 담고 있는 각각의 노드이다.
* 텐서로 구성되어 있는 가중치 덩어리를 합성곱 연산을 해주고 그 값을 다음 노드로 넘겨주고 있다.
* Input data 역시 텐서로 구성되어 있고 이것을 넘겨주는 것도 결국 텐서로 구성되어 있다.
* 결과적으로 텐서의 흐름으로 무언가를 만들고 있기 떄문에 TensorFlow 이다.
* 자 여기서 만약에 빨간색의 수직 윤곽선만 떼오고 싶다면 필터는,

$$
RED = \begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1 \end{bmatrix}\\ GRN = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}\\ BLU = \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}\\
$$

* 와 같이 표현 가능하다.
* 그런데 만약 수직선과 수평선을 동시에 따오고 싶으면 어떻게 할까?

![](convolution8.png)

* 다음과 같은 상황에서,
* 노란색 = Vertical
* 주황섹 = Horizontal 필터라고 해보자.
* 이 경우 나온 출력은 4 x 4 가 2개가 나올 것이다.
* 이 두개를 내가 한꺼번에 쓴다면, 4 x 4 x 2 이다.
* 내가 RGB 채널에 각각 들어가는 필터를 어떤 하나의 단위처럼 본다면,
* 다시 말해서 위 그림에서 노란색 필터, 주황색 필터와 같이 2개의 필터가 있다고 생각한다면,
* 출력의 채널 수는, 내가 사용한 필터의 개수에 따라 결정된다.

$$
Input;=;n\times n \times n_c\\ Filter;=;f\times f \times n_c\\ Output;=;({n+2p-f\over s} + 1)\times ({n+2p-f\over s} + 1) \times n_c^\prime\\ n_c는 ;채널;수\\ n_c^\prime는;필터;수
$$

* 여기서 핵심적인 것은,
* 내가 필요한 필터들을 이미지에 다 걸어버린 후
* 이것들을 한데모아 다같이 평가할 수 있다는 것이다!
* **즉 검출하고자 하는 특성의 수만큼 출력의 채널을 갖게 된다!**
