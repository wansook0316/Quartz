---
title: Structured Probabilistic Model
thumbnail: ''
draft: false
tags:
- machine-learning
created: 2024-10-22
---

# 다변수 확률 분포의 복잡성

* 기계 학습 알고리즘을 확률 분포로 생각해보자.
* 굉장히 많은 확률 변수가 관여함에도, 비교적 적은 수의 변수들만 서로간의 직접적인 상호작용을 갖는다.
  * 즉, 대부분은 독립적인 확률변수이고, 몇몇만 종속적이다.
* 이러한 특이성을 가짐에도 확률분포를 하나의 함수로 나타내는 것은 매우 비효율적이다.
* 예를 들어, 확률 변수 a, b, c가 있다하자.
  * a -> b: B는 A에 종속
  * b -> c: C는 B에 종속
  * a, b는 독립
  * b, c는 독립
* 위와 같은 상황에서 $p(a, b, c)$는 다음과 같이 표현된다.
  * [Chain Rule](Chain%20Rule.md)과 독립 사건의 원리를 사용하면 된다.

$$
p(a, b, c) = p(a) \cdot p(b | a) \cdot p(c | a, b) = p(a) \cdot p(b|a) \cdot p(c|b)
$$

# 효과

* 위와 같이 다변수 분포를 인수분해할 경우, [Parameter](Parameter.md)의 개수를 줄일 수 있다.
  * 확률 변수의 개수가 줄어들면, 해당 확률 변수를 사용하는 분포의 [Parameter](Parameter.md)를 적게 쓸 수 있다.
  * $p(a, b)$에서 사용하는 [Parameter](Parameter.md)보다 $p(a)$를 서술할 때 필요한 [Parameter](Parameter.md)가 당연히 적게 필요하다.
* 각 인수가 사용하는 [Parameter](Parameter.md)들의 개수는 그 인수에 있는 변수 개수의 곱에 비례한다.
  

# [Parameter](Parameter.md)개수가 급증하는 이유

$$
p(a, b, c) = p(a) \cdot p(b | a) \cdot p(c | b)
$$

* $p(a)$ 
  * 변수  $a$ 에 대한 확률.
  * 예를 들어,  a 가 이산형 변수로  $k$ 개의 상태를 가질 수 있다면, 이 확률을 정의하기 위해  $k-1$ 개의 매개변수가 필요합니다.
  * 혹은 연속형 변수라고 하더라도, 어떤 분포를 쓰냐에 따라 파라미터의 개수는 달라질 수 있다.
* $p(b | a)$
  * 이는 $a$ **의 상태에 따라 $b$의 확률이 달라지는 조건부 확률**이다.
  * 만약  $a$ 가  $k$ 개의 상태를 가질 수 있고,
  * $b$ 가  $l$ 개의 상태를 가질 수 있다면,  $p(b | a)$ 는 각  $a$ 의 상태에 대해  $b$ 의 확률을 정의해야 한다. 
  * 따라서 이 경우 필요한 매개변수의 수는 $k \times (l - 1)$ 다. 
  * 각 상태에 대해  l-1 개의 매개변수를 가지니까, 모든 상태에서 거듭 제곱처럼 증가합니다.
* $p(c | b)$
  * 마찬가지로 $b$의 상태에 따라 $c$의 확률이 달라진다.
  * $b$ 가  $l$ 개의 상태를,  $c$ 가  $m$ 개의 상태를 가질 수 있다면, 이 조건부 확률을 표현하려면 $l \times (m-1)$ 개의 매개변수가 필요하다.

# 구조적 확률 모형

* 이런 인수분해를 **그래프**로 표현할 수 있다.
* [Graph](../Discrete%20Mathematics/Graph.md)
