---
title: Self Information
thumbnail: ''
draft: false
tags:
- infomation-theory
created: 2024-10-21
---

# 직관

* 발생 가능성이 낮은 사건이 발생 가능성이 높은 사건보다 더 많은 "정보"를 얻을 수 있다.
  * 즉, 항상 발생하는 사건은 정보가 없다.
  * 반대로 간헐적으로 발생한다면 정보가 많다.
* 위 생각에 동의한다면, 이를 수치화 할 수 있어야 한다.
* 이를 수치화하기 위해 필요한 성질은 아래와 같다.

# 성질

1. 발생 가능성이 큰 사건은 정보량이 적어야 한다. 반드시 발생한다면 해당 사건의 정보는 0이다.
1. 발생 가능성이 낮은 사건은 정보량이 많아야 한다.
1. 개별 사건들의 정보량을 더할 수 있어야 한다.
   * 예를 들어, 동전을 두 번 던져서 두 번 다 앞면이 나온 사건의 정보량은 한번 던져 앞면이 나온 정보량의 두배여야 한다.

# Self-infomation

$$
I(x) = -\log P(x)
$$

* 위의 로그 밑은 $e$이다.
* 이런 경우 해당 단위는 nat이라고 부른다.
* 1nat은 확률이 $\frac{1}{e}$인 사건이 발생했을 때 얻는 정보량이다.
* 밑이 2인 경우는 bit 혹은 shannon이라고 부른다.
* 자기 정보는 오직 **하나의 결과만 다룬다.**
* 확률 분포 전체의 불확실성은 [Information Entropy](Information%20Entropy.md)를 사용한다.
